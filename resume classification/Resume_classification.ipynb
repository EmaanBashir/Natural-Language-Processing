{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume classification",
      "provenance": [],
      "collapsed_sections": [
        "g1J4KdY9hfNN",
        "yroJWYa1j-Kq",
        "c1NzqHomRXIm"
      ],
      "authorship_tag": "ABX9TyOiUD7SCxhrmw92b+GPNDFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmaanBashir/Natural-Language-Processing/blob/main/resume%20classification/Resume_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Vw7sA4QRJ-"
      },
      "source": [
        "## **Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqD6wfrUQRmm",
        "outputId": "939a995f-dfa8-490d-c0c6-3c237244457e"
      },
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install docx2txt\n",
        "!pip install unidecode\n",
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.20)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-3.4.7 pdfminer.six-20201018\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3982 sha256=bc89390bfa6bad1a29ff621da1714c2618e4c594ccbc30a4ce99782416378c81\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 8.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 55.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85442 sha256=e656267ad9cdc73e816f200a72a55baf71a9016faf366145969510c683c5ac0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvEM8uieMHF3"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beg5ezHRMUfJ"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import unidecode\n",
        "import re\n",
        "import contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U84TO-S0Qrxl"
      },
      "source": [
        "## **Extract Data**\n",
        "Extract data from a pdf or word file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNzm0ptsRCCK"
      },
      "source": [
        "### **Pdf file**\n",
        "Upload a file file.pdf. Then run the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDVo3vDRIwZ",
        "outputId": "94418b0c-7e27-4a9b-c2b2-914f4f518602"
      },
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def extract_from_pdf(path):\n",
        "  return extract_text(path)\n",
        "\n",
        "print(extract_from_pdf(\"./file.pdf\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Curriculum Vitae\n",
            "\n",
            "Olivia Karina Peter (Ms)\n",
            "Mobile: +65 8406 9099\n",
            "Email: oliviapeter@hotmail.com\n",
            "\n",
            "Background\n",
            "\n",
            " Regulatory compliance specialist, particularly in the area of Anti-Money Laundering and\n",
            "Countering Financing of Terrorism (AML/CFT) and regulations for banks and capital\n",
            "markets services licence holders.\n",
            "\n",
            " Over 6 years of experience auditing financial institutions in Singapore and New Zealand and\n",
            "\n",
            "currently specialises in providing regulatory compliance advisory services.\n",
            "\n",
            " Developed strong project management and communication skills through the planning and\n",
            "coordination of audits with various stakeholders in order to produce multiple deliverables\n",
            "within tight deadlines.\n",
            "\n",
            "Education\n",
            "\n",
            "Bachelors of Accounting (Hons) from Nanyang Technological University (Singapore)\n",
            "\n",
            "\n",
            " Member of Certified Practising Accountants of Australia (“CPA Australia”)\n",
            "\n",
            "Professional Experiences\n",
            "\n",
            "Manager\n",
            "Regulatory Advisory Services\n",
            "PricewaterhouseCoopers Risk Services Pte. Ltd., Singapore\n",
            "\n",
            "Dec 2014 to present\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Subject Matter Expert (“SME”) for a team of 30 staff performing client due diligence reviews\n",
            "for a Swiss bank undergoing acquisition. The scope included the review of 400+ high risk\n",
            "accounts within 6 weeks and required coordination and communication with various\n",
            "stakeholders in both the acquirer and target banks. This included tabling of risks associated\n",
            "with accounts as well as mitigating factors to senior management for their decision making.\n",
            "\n",
            "Subject Matter Expert (“SME”) and Team Leader for a KYC remediation project. Assisted a\n",
            "British bank in performing a one-off ‘back-book’ file review and remediation exercise for\n",
            "Hong Kong and Singapore booked and/or managed client accounts (approximately 4,300\n",
            "accounts in total). Aspects of the file review and remediation processing included among\n",
            "others, the assessment of the risk rating of the Bank’s clients, performing a gap analysis of\n",
            "the KYC, performing adverse news checks, transaction reviews and the profiling of the Bank’s\n",
            "clients source of wealth with the assistance of the bankers.\n",
            "\n",
            "Provided annual regulatory audit support and assessed clients’ compliance to Anti-Money\n",
            "Laundering Guidelines and regulators expectations for PwC’s bank clients as part of their\n",
            "reporting to the Monetary Authority of Singapore. For the gaps identified, provide\n",
            "recommendations based on our experience/understanding of\n",
            "regulator’s\n",
            "expectations and industry practices. PwC’s bank clients include retail, commercial and\n",
            "private banking institutions.\n",
            "\n",
            "the local\n",
            "\n",
            "\f\n",
            "\n",
            "Performed gap analysis and recommended enhancements to a foreign bank's wire transfer\n",
            "policies and procedures in line with Singapore regulations and industry standards.\n",
            "\n",
            " Conducted internal AML trainings for the assurance department\n",
            "\n",
            "Senior Associate\n",
            "Financial Services\n",
            "PricewaterhouseCoopers (“PwC”) New Zealand, Auckland Office\n",
            "\n",
            "Nov 2013 to Nov 2014\n",
            "\n",
            " Understanding and evaluating client’s business processes and formulating the audit plan\n",
            "\n",
            "based on the assessed risks with the goal to increase audit efficiency.\n",
            "\n",
            "\n",
            "\n",
            "Liaising with the various lines of services within the firm and the PwC international network\n",
            "as well as the clients finance team.\n",
            "\n",
            " Review of capital adequacy calculations and disclosures to ensure its compliance with the\n",
            "\n",
            "capital adequacy framework as mandated by the Reserve Bank of New Zealand.\n",
            "\n",
            "\n",
            "\n",
            "Preparation of audit reports that were presented to the audit committee and management.\n",
            "\n",
            " Key clients include ASB Banking Group (ASB Bank, CBA and the ASB managed funds).\n",
            "\n",
            "Assistant Manager\n",
            "Financial Services Industry Practice\n",
            "PricewaterhouseCoopers LLP, Singapore\n",
            "\n",
            "Dec 2009 to Nov 2013\n",
            "\n",
            " Understanding and evaluating client’s business processes (including their dependencies on\n",
            "the systems and processes in their Head Office) and formulating the audit plan based on\n",
            "these factors.\n",
            "\n",
            " Coordinate between various senior stakeholders in the banks (e.g. head of departments,\n",
            "\n",
            "business process owners) as well as PwC teams in AsiaPac, US and UK and cross function\n",
            "teams.\n",
            "\n",
            "\n",
            "\n",
            "Preparation of the Audit Long Form Report (“ALFR”) which is submitted to the Monetary\n",
            "Authority of Singapore for Singapore registered banks and branches. The ALFR includes\n",
            "control deficiencies observed in the bank and recommendations for enhancements in line\n",
            "with industry practice and regulators expectations.\n",
            "\n",
            " Key clients include Commerzbank AG (Singapore Branch), Macquarie Capital Securities,\n",
            "Maybank Kim Eng Holdings Group, Hong Leong Bank (Singapore Branch), DBS Vickers\n",
            "Singapore, BNP Paribas Securities Singapore and Schroder & Co. (Asia).\n",
            "\n",
            "Awards\n",
            "\n",
            "Singapore Scholar, Singapore Ministry of Foreign Affairs (2006)\n",
            "\n",
            "\n",
            " Awarded the PwC Experience Award by PwC HK and China –Recognise 2016 for dedication\n",
            "\n",
            "to collaboration and sharing.\n",
            "\n",
            "\f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAVf64D0T0HB"
      },
      "source": [
        "### **Word file(.docx)**\n",
        "Upload a file file.docx. Then run the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29U2meDxT-jZ",
        "outputId": "b6825441-8174-4942-cada-dcc8d70bdbbf"
      },
      "source": [
        "import docx2txt\n",
        "\n",
        "def extract_from_docx(path):\n",
        "  return docx2txt.process(path)\n",
        "\n",
        "print(extract_from_docx(\"./file.docx\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Curriculum VitaeOlivia Karina Peter (Ms)\n",
            "\n",
            "Mobile: +65 8406 9099\n",
            "\n",
            "Email: oliviapeter@hotmail.com\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Background\n",
            "\n",
            "\n",
            "\n",
            "\tRegulatory compliance specialist, particularly in the area of Anti-Money Laundering and Countering Financing of Terrorism (AML/CFT) and regulations for banks and capital markets services licence holders.\n",
            "\n",
            "\n",
            "\n",
            "\tOver 6 years of experience auditing financial institutions in Singapore and New Zealand and currently specialises in providing regulatory compliance advisory services.\n",
            "\n",
            "\n",
            "\n",
            "\tDeveloped strong project management and communication skills through the planning and coordination of audits with various stakeholders in order to produce multiple deliverables within tight deadlines.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Education\n",
            "\n",
            "\n",
            "\n",
            "\t\tBachelors of Accounting (Hons) from Nanyang Technological University (Singapore)\n",
            "\n",
            "\t\tMember of Certified Practising Accountants of Australia (“CPA Australia”)\n",
            "\n",
            "\n",
            "\n",
            "Professional Experiences\n",
            "\n",
            "\n",
            "\n",
            "\tManager\tDec 2014 to present\n",
            "\n",
            "Regulatory Advisory Services\n",
            "\n",
            "PricewaterhouseCoopers Risk Services Pte. Ltd., Singapore\n",
            "\n",
            "\n",
            "\n",
            "\tSubject Matter Expert (“SME”) for a team of 30 staff performing client due diligence reviews for a Swiss bank undergoing acquisition. The scope included the review of 400+ high risk accounts within 6 weeks and required coordination and communication with various stakeholders in both the acquirer and target banks. This included tabling of risks associated with accounts as well as mitigating factors to senior management for their decision making.\n",
            "\n",
            "\n",
            "\n",
            "\tSubject Matter Expert (“SME”) and Team Leader for a KYC remediation project. Assisted a British bank in performing a one-off ‘back-book’ file review and remediation exercise for Hong Kong and Singapore booked and/or managed client accounts (approximately 4,300 accounts in total). Aspects of the file review and remediation processing included among others, the assessment of the risk rating of the Bank’s clients, performing a gap analysis of the KYC, performing adverse news checks, transaction reviews and the profiling of the Bank’s clients source of wealth with the assistance of the bankers.\n",
            "\n",
            "\n",
            "\n",
            "\tProvided annual regulatory audit support and assessed clients’ compliance to Anti-Money Laundering Guidelines and regulators expectations for PwC’s bank clients as part of their reporting to the Monetary Authority of Singapore. For the gaps identified, provide recommendations based on our experience/understanding of the local regulator’s expectations and industry practices. PwC’s bank clients include retail, commercial and private banking institutions.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPerformed gap analysis and recommended enhancements to a foreign bank's wire transfer policies and procedures in line with Singapore regulations and industry standards.\n",
            "\n",
            "\n",
            "\n",
            "\t\tConducted internal AML trainings for the assurance department\n",
            "\n",
            "\tSenior Associate\tNov 2013 to Nov 2014\n",
            "\n",
            "Financial Services\n",
            "\n",
            "PricewaterhouseCoopers (“PwC”) New Zealand, Auckland Office\n",
            "\n",
            "\n",
            "\n",
            "\t\tUnderstanding and evaluating client’s business processes and formulating the audit plan based on the assessed risks with the goal to increase audit efficiency.\n",
            "\n",
            "\n",
            "\n",
            "\t\tLiaising with the various lines of services within the firm and the PwC international network as well as the clients finance team.\n",
            "\n",
            "\n",
            "\n",
            "\t\tReview of capital adequacy calculations and disclosures to ensure its compliance with the capital adequacy framework as mandated by the Reserve Bank of New Zealand.\n",
            "\n",
            "\n",
            "\n",
            "\t\tPreparation of audit reports that were presented to the audit committee and management.\n",
            "\n",
            "\n",
            "\n",
            "\t\tKey clients include ASB Banking Group (ASB Bank, CBA and the ASB managed funds).\n",
            "\n",
            "\tAssistant Manager\tDec 2009 to Nov 2013\n",
            "\n",
            "Financial Services Industry Practice PricewaterhouseCoopers LLP, Singapore\n",
            "\n",
            "\n",
            "\n",
            "\t\tUnderstanding and evaluating client’s business processes (including their dependencies on the systems and processes in their Head Office) and formulating the audit plan based on these factors.\n",
            "\n",
            "\n",
            "\n",
            "\t\tCoordinate between various senior stakeholders in the banks (e.g. head of departments, business process owners) as well as PwC teams in AsiaPac, US and UK and cross function teams.\n",
            "\n",
            "\n",
            "\n",
            "\t\tPreparation of the Audit Long Form Report (“ALFR”) which is submitted to the Monetary Authority of Singapore for Singapore registered banks and branches. The ALFR includes control deficiencies observed in the bank and recommendations for enhancements in line with industry practice and regulators expectations.\n",
            "\n",
            "\n",
            "\n",
            "\tKey clients include Commerzbank AG (Singapore Branch), Macquarie Capital Securities, Maybank Kim Eng Holdings Group, Hong Leong Bank (Singapore Branch), DBS Vickers Singapore, BNP Paribas Securities Singapore and Schroder & Co. (Asia).\n",
            "\n",
            "\n",
            "\n",
            "Awards\n",
            "\n",
            "\n",
            "\n",
            "\t\tSingapore Scholar, Singapore Ministry of Foreign Affairs (2006)\n",
            "\n",
            "\t\tAwarded the PwC Experience Award by PwC HK and China –Recognise 2016 for dedication to collaboration and sharing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6zU3Ku0iloy"
      },
      "source": [
        "### **Word or pdf file**\n",
        "Upload a word or pdf file(file.docx or file.pdf). Then run the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRyLa7-aiq2x"
      },
      "source": [
        "def extract_data(file):\n",
        "  extension = file.split('.')[-1]\n",
        "  \n",
        "  if extension.lower() == 'pdf':\n",
        "    text = extract_from_pdf(file)\n",
        "  elif extension.lower() == 'docx':\n",
        "    text = extract_from_docx(file)\n",
        "  else:\n",
        "     return \"Only pdf and docx files acceptable\"\n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1J4KdY9hfNN"
      },
      "source": [
        "## **Text Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZoFGBFWdscA"
      },
      "source": [
        "### **Tokenization and Removing punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7neM7riRqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc04218a-2bf5-4b26-8353-75c2e8e9f705"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "def tokenize(text):\n",
        "  return tokenizer.tokenize(text)\n",
        "\n",
        "print(tokenize(\"Let us get the most common words adn then remove them in the next step!\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Let', 'us', 'get', 'the', 'most', 'common', 'words', 'adn', 'then', 'remove', 'them', 'in', 'the', 'next', 'step']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qGyOCxwjI-b"
      },
      "source": [
        "### **Remove stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GCHQ3iwjN_6",
        "outputId": "eea53aba-702d-416c-aead-05605dc5e6ae"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stop_words(text):\n",
        "  return [x for x in text if x not in stopwords.words('english')]\n",
        "\n",
        "print(remove_stop_words(tokenize(\"Let us get the most common words adn then remove them in the next step\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['Let', 'us', 'get', 'common', 'words', 'adn', 'remove', 'next', 'step']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA-gmsFnlDrd"
      },
      "source": [
        "### **Lemmatizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obSsb17slMUs",
        "outputId": "1211b4f7-fe4f-4375-c8e3-a451d6acedbc"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "  return [lemmatizer.lemmatize(x) for x in text]\n",
        "\n",
        "print(lemmatize(tokenize(\"Let us get the most common words adn then remove them in the next step\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "['Let', 'u', 'get', 'the', 'most', 'common', 'word', 'adn', 'then', 'remove', 'them', 'in', 'the', 'next', 'step']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-NITREWGdKD"
      },
      "source": [
        "### **Lower casing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLe6Cwg7GsR1",
        "outputId": "8a732edb-a219-4582-d3eb-8a0375c84b8d"
      },
      "source": [
        "def lower_case(text):\n",
        "\n",
        "  for x in range (len(text)):\n",
        "    text[x] = text[x].lower()\n",
        "\n",
        "  return text\n",
        "\n",
        "print(lower_case([\"sdfF\", \"sSSDF\", \"TTT\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sdff', 'sssdf', 'ttt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FfvcMiIozaO"
      },
      "source": [
        "### **Removal of Urls**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6rxUXEXSMc1",
        "outputId": "132faac8-23db-465e-e621-aa5845328a1a"
      },
      "source": [
        "def remove_urls(text):\n",
        "  \n",
        "  pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return pattern.sub(r'', text)\n",
        "\n",
        "print(remove_urls(\"Check this out: https://colab.research.google.com/drive/15mvNXz1_5rfmWHt1uOg8PDKeCeUWl7t2#scrollTo=p6rxUXEXSMc1\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check this out: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM9cHWoakh-H"
      },
      "source": [
        "### **Remove RT and cc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_rKsjdKko7k"
      },
      "source": [
        "def remove_rtt_cc(text):\n",
        "  return re.sub('RT|cc', ' ', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKdY3drIod4Q"
      },
      "source": [
        "### **Remove hashtags and mentions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnJ2RKU2oj_a"
      },
      "source": [
        "def remove_hashtags_mentions(text):\n",
        "  text = re.sub('#\\S+', '', text)\n",
        "  text = re.sub('@\\S+', '  ', text)\n",
        "  return text "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYc3os_IpkPg"
      },
      "source": [
        "### **Conversion of Accented Characters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1g6SVG98RVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f53257-9979-4826-e9ba-4a3104b8dbd1"
      },
      "source": [
        "def convert_accented_characters(text):\n",
        "  return unidecode.unidecode(text)\n",
        "\n",
        "print(convert_accented_characters(\"Words with accent marks like “latté” and “café” \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words with accent marks like \"latte\" and \"cafe\" \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYchSKGJgCCj"
      },
      "source": [
        "### **Expand contractions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Qdvfp8sCBe",
        "outputId": "76b2aa56-88ba-4532-f59f-b2a895919098"
      },
      "source": [
        "def expand_contractions(text):\n",
        "  return contractions.fix(text)\n",
        "\n",
        "print(expand_contractions(\"Dont do this\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "do not do this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLWlxdB5jdws"
      },
      "source": [
        "### **Pre-processing functions combined**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfoxQcRNjiK5"
      },
      "source": [
        "def pre_process(text):\n",
        "\n",
        "  text = remove_urls(text)\n",
        "  text = remove_rtt_cc(text)\n",
        "  text = remove_hashtags_mentions(text)\n",
        "  text = expand_contractions(text)\n",
        "  text = tokenize(text)\n",
        "  text = remove_stop_words(text)\n",
        "  text = lemmatize(text)\n",
        "  text = lower_case(text)\n",
        "  text = ' '.join(map(str, text))\n",
        "  text = convert_accented_characters(text)\n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yroJWYa1j-Kq"
      },
      "source": [
        "## **Encode Categories**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7dxvkRykB9H"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode_categories(encoder, dataset, category):\n",
        "  dataset[category] = encoder.fit_transform(dataset[category])\n",
        "  return encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1NzqHomRXIm"
      },
      "source": [
        "## **Resume Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fINysFb7kdei"
      },
      "source": [
        "### **Training**\n",
        "The file \"resumeDataSet.csv\" is available at https://drive.google.com/file/d/19FtWACUs3gMz4zNPnVPKr4dOijemJRFt/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou3O1CnlknQj"
      },
      "source": [
        "1) Read .csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dawBgozxUe5d",
        "outputId": "de1f0451-2ac1-428e-f1e3-f657d49f6fc7"
      },
      "source": [
        "dataset = pd.read_csv(\"./resumeDataSet.csv\", encoding = \"utf-8\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Category                                             Resume\n",
              "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
              "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
              "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
              "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
              "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrfV7HKjkwru"
      },
      "source": [
        "2) Pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wPRQo0-RiG5x",
        "outputId": "5d0ddea9-0a11-4293-8df5-b67c44f932f7"
      },
      "source": [
        "dataset['Resume'] = dataset.Resume.apply(lambda x: pre_process(x))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>skills programming languages python panda nump...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>education details may 2013 may 2017 b e uit rg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>areas interest deep learning control system de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>skills a a python a sap hana a tableau a sap h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Science</td>\n",
              "      <td>education details mca ymcaust faridabad haryan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Category                                             Resume\n",
              "0  Data Science  skills programming languages python panda nump...\n",
              "1  Data Science  education details may 2013 may 2017 b e uit rg...\n",
              "2  Data Science  areas interest deep learning control system de...\n",
              "3  Data Science  skills a a python a sap hana a tableau a sap h...\n",
              "4  Data Science  education details mca ymcaust faridabad haryan..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz_q-pDKk6U0"
      },
      "source": [
        "3) Encode categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_TR7gBl_poEq",
        "outputId": "dcebc916-ce31-443f-bd1a-20abca420e1c"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encode_categories(encoder, dataset, \"Category\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Resume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>skills programming languages python panda nump...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>education details may 2013 may 2017 b e uit rg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>areas interest deep learning control system de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>skills a a python a sap hana a tableau a sap h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>education details mca ymcaust faridabad haryan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Category                                             Resume\n",
              "0         6  skills programming languages python panda nump...\n",
              "1         6  education details may 2013 may 2017 b e uit rg...\n",
              "2         6  areas interest deep learning control system de...\n",
              "3         6  skills a a python a sap hana a tableau a sap h...\n",
              "4         6  education details mca ymcaust faridabad haryan..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfDsGxp-k982"
      },
      "source": [
        "4) Vectorize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gYNn7SCt_Kq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "resume = dataset[\"Resume\"].values\n",
        "categories = dataset[\"Category\"].values\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(sublinear_tf=True, max_features=1500)\n",
        "word_vectorizer.fit(resume)\n",
        "word_features = word_vectorizer.transform(resume)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI8riTyAlKGn"
      },
      "source": [
        "5) Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuoZymw-lPna",
        "outputId": "8612f885-4be9-4f0d-9421-3820ce57ff3c"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(word_features, categories, random_state=0, test_size=0.2)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:  (769, 1500)\n",
            "X_test:  (193, 1500)\n",
            "y_train:  (769,)\n",
            "y_test:  (193,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLzfOGcHlnjk"
      },
      "source": [
        "6) Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjYPdjO_wFJs",
        "outputId": "385ac3e0-bfaf-43be-de30-f8e48a60f0a4"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier = OneVsRestClassifier(KNeighborsClassifier())\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto',\n",
              "                                                   leaf_size=30,\n",
              "                                                   metric='minkowski',\n",
              "                                                   metric_params=None,\n",
              "                                                   n_jobs=None, n_neighbors=5,\n",
              "                                                   p=2, weights='uniform'),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6yITZk1lwGj"
      },
      "source": [
        "7) Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-APl0bABlyp3",
        "outputId": "f5edffe3-7e6f-48b3-f1cf-3b5f5758c975"
      },
      "source": [
        "print(\"Training set accuracy: \", classifier.score(X_train, y_train))\n",
        "print(\"Test set accuracy: \", classifier.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy:  0.9960988296488946\n",
            "Test set accuracy:  0.9896373056994818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ilHLy_EmNyw"
      },
      "source": [
        "### **Classify Resume**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2SlrXkBmVnZ"
      },
      "source": [
        "def classify_resume(resume):\n",
        "  data = extract_data(resume)\n",
        "  cleaned_data = pre_process(data)\n",
        "  transformed = word_vectorizer.transform([cleaned_data])\n",
        "  category = encoder.inverse_transform(classifier.predict(transformed))\n",
        "\n",
        "  return category"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzt0P0ISl7nP"
      },
      "source": [
        "### **Test the model on your own cv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6FGz-vNzejW",
        "outputId": "39b59b11-8be9-4ce1-f84b-09780f93b689"
      },
      "source": [
        "print(classify_resume(\"./file.pdf\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Operations Manager']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}